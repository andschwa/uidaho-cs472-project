#+TITLE:     Project #1b Genetic Algorithm
#+AUTHOR:    Andrew Schwartzmeyer
#+EMAIL:     schw2620@vandals.uidaho.edu
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+BEGIN_abstract
This assignment built on Project #2b by adding a simple Genetic
Algorithm. This implementation in C++ used a generational population,
with a unit Gaussian mutation function, and roulette wheel
selection. It faired decently, but has much room for improvement.
#+END_abstract

* Assignment :noexport:
   DEADLINE: <2014-02-12 Wed>
This is the second subproject. The goal of this project is to write
part of a genetic algorithm (GA) for one of the benchmark optimization
problems.

For this subproject you only need to work on the Spherical function,
defined at [[http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume24/ortizboyer05a-html/node6.html#tabla:DefFunc][here]]. (Note the first function labeled as Schwefel on this
page is actually the double sum, which we are not using. We are using
the Schwefel function defined immediately after the Rastigin
function.)

Pay careful attention to the ranges of the functions. You will want to
use those ranges both in creating initial individuals and in
controlling the generation of neighbors, e.g. you don't want your GA
'wandering' out of the search space. Note that here the functions are
all defined with 30 dimensions, e.g. P = 30 in the function
definitions.

*** Task
Write a partial GA to find the input values (x_{1}, ... ,x_{30}) that
minimizes the Spherical function.

The GA should include the following:
- Fitness function
- Algorithm type: steady state or generational
- Selection
- Mutation
- Note: you don't need crossover for this part
*** Write-up
Write a short paper describing the results of your project that
includes the following sections:
- Algorithm descriptions: Description of the GA so far. Be careful to
  include all of the details someone would need to replicate your
  work.
- Results: Basically, does it seem to be working.
- Conclusions: If its not working, why not. And what are then next
  steps to complete the project.
* Notes :noexport:
** Functions
*** Spherical
f_{Sph}(x) = (\sum_{i=1})^{p} (x_{i})^{2}
x_{i} \in [-5.12, 5.12]
x^{\*} = (0, 0, ..., 0); f_{Sph}(x^{\*}) = 0

Use fewer random restarts, more neighbors
*** Schwefel
f_{Sch}(x) = 418.9829 \cdot p + (\sum_{i=1})^{p} x_{i }sin(\radic|x_{i}|)
x_{i} \in [-512.03, 511.97]
x^{\*} = (-420.9687, ..., -420.9687); f_{Sch}(x^{\*}) = 0

Use more random restarts, fewer neighbors
** Algorithms
*** Hill Climbing
- generate a random solution s_{1}
- do random restart until a good enough solution is found
  - do until no better neighbor
    - pick a neighbor solution s_{2}
    - if s_{2} is better than s_{1}
      - s_{1} \gets s_{2}
    - loop
  - loop
*** Simulated Annealing
- pick a random solution s_{1}
- for T = 100 to 0 step -.1
  - pick a neighbor of s_{1}, s_{2}
  - if s_{2} is better than s_{1}
    - s_{1} \gets s_{2}
  - else
    - with probability P(e_{1}, e_{2}, T)
    - s_{1} \gets s_{2} anyway
    - where e_{1} is the fitness/energy of s, e_{2} of 2

- P(e_{1}, e_{2} T) = e^{-c(e_{1} - e_{2})/T} = 1/e^{(e_{1} - e_{2})/T}
- Scaling constant c to adjust probabilites

- S_{current best}
- F_{current best} = f(S_{current best})
- For temperature ...
  - generate S_{next}
  - F_{next} = f(S_{next})
  - if (F_{next} > F_{current best} || P(F_{next}, F_{current best}, T) < T)
    - S_{current best} \gets S_{next}
    - F_{current best} \gets F_{next}
** Results
*** Spherical
**** Hill-climbing
With goal = 10, filter = 100, neighbors = 100000000, delta = 0.1:

Random restart - fitness is: 99.1383
Neighbors exhausted - fitness was: 0.0363001
0.0599998 -0.0299992 -0.02 -0.0399999 0.04 0.0400003 0.00999989 0.0300003 0.0100001 0.0399996 0.0499996 -0.0300023 0.0600003 -0.0300004 -0.04 1.49012e-08 -0.0600001 0.04 7.45058e-08 -0.01 -0.0400003 0.00999971 -0.00999989 0.0300002 7.45058e-08 0.0399999 0.04 7.45058e-08 -0.0400002 -0.04 
Spherical function value is: 0.0363001
Fitness is: 0.0363001
./search  51.32s user 0.07s system 99% cpu 51.424 total

Random restart - fitness is: 98.4617
Neighbors exhausted - fitness was: 0.0296999
0.00999977 -1.49012e-08 -0.02 -0.0299998 -0.0200001 -0.0300002 -0.0500001 -0.00999989 -0.0499999 0.03 -0.0699997 0.0299998 -0.0299996 -0.0100013 0.02 -0.0300008 -0.00999989 0.0100001 0.02 0.05 -0.00999923 0.0299999 -0.03 0.03 -0.0199998 0.02 0.0100001 -0.0300002 0.0599998 -0.04 
Spherical function value is: 0.0296999
Fitness is: 0.0296999
./search  56.61s user 0.06s system 99% cpu 56.695 total
**** Simulated Annealing
With goal = 10, filter = 100, steps = 100000, delta = 0.01, c = -1000:

Random restart - fitness is: 99.8699
Temperature zero - fitness was: 0.00639894
-0.0300001 -1.47521e-06 2.83122e-07 0.0200013 0.0100015 0.0100003 0.0299985 -1.63913e-06 -0.0199928 -0.00999996 0.02 0.0200007 -0.0200013 0.0199994 -0.02 -0.0100016 4.02331e-07 -0.0299995 -5.06639e-07 2.68221e-07 9.08971e-07 0.00999814 -0.00999998 -1.19209e-07 0.0100005 0.00996085 0.00999896 3.8743e-07 1.38581e-06 -1.38581e-06 
Spherical function value is: 0.00639894
Fitness is: 0.00639894
./search  5.95s user 0.02s system 99% cpu 5.980 total

Random restart - fitness is: 71.44
Temperature zero - fitness was: 0.00380014
0.00999994 6.25849e-07 -1.93715e-07 -0.0100016 0.00999998 1.10269e-05 -0.0200011 -0.00999981 1.19209e-07 -0.0199996 -0.0199988 0.01 0.0100005 0.0200018 -0.0100003 0.0200018 0.0100003 -0.0199985 0.0100003 -6.4075e-07 0.0100003 1.49012e-08 -2.5332e-07 -0.00999969 -0.00999885 1.40071e-06 -0.0100006 2.5779e-06 0.0100015 1.38581e-06 
Spherical function value is: 0.00380014
Fitness is: 0.00380014
./search  13.92s user 0.05s system 97% cpu 14.263 total
*** Schwefel
**** Hill-climbing
With goal = 5000, filter = 10000, neighbors = 10000000, and delta = 10:

Random restart - fitness is: 8257.8
Neighbors exhausted - fitness was: 4063.14
-205.88 -420.96 -420.94 -416.53 -65.72 -205.52 302.99 -424.19 -205.69 -62.04 -201.71 26.81 -427.71 306.48 -198.3 -421.6 -419.46 -415.42 -70.59 -420.82 -200.77 -417.81 32.69 -421.01 -423.52 -419.48 502.17 124.02 -420.36 299.66 
Schwefel function value is: 4063.14
Fitness is: 4063.14
./search  12.00s user 0.04s system 99% cpu 12.107 total

Random restart - fitness is: 9854.36
Neighbors exhausted - fitness was: 4928.45
301.63 -1.59 301.09 -417.76 23.6 306.72 -421.32 299.72 -422.56 307.45 -202.5 28.89 310.15 123.67 -204.22 -413.49 -203.01 300.86 -201.67 -202.1 508.68 -204.12 -424.61 28.06 128.7 -419.72 -415.56 301.55 -419.7 131.06 
Schwefel function value is: 4928.45
Fitness is: 4928.45
./search  11.75s user 0.02s system 97% cpu 12.092 total
**** Simulated Annealing
With goal = 3000, filter = 10000, steps = 10000000, constant = -10,
and delta = 10:

-201.95 506.49 302.65 294.04 -209.06 308.65 305.98 -416.03 293.45 -421.27 -417.68 -419.1 125.97 503.21 -413 302.29 -424.58 -422.48 304.21 -205.77 -423.43 -421.47 298.14 -421.91 300.77 -427.16 303.8 313.87 -420.16 304.25 
Schwefel function value is: 2813.62
Fitness is: 2813.62
./search  12.73s user 0.06s system 97% cpu 13.166 total

306.71 -418.9 309.1 306.14 303.21 502.45 -420.97 301.53 309.97 304.83 292.7 305.89 -415.82 -414.75 306.96 306.81 507.15 507.85 304.2 -418.51 310.43 511.78 300.89 509.13 295.15 302.67 302.44 299.53 -417.17 -415.57 
Schwefel function value is: 2990.2
Fitness is: 2990.2
./search  87.90s user 0.26s system 99% cpu 1:28.90 total

** OOD
*** Classes
**** Algorithm
- goal
- filter
- iterations

**** Individual
- solution data structure
- mutation
- initial generation

**** Problem
- fitness function
- fitness normalization
- range
- delta / mututation bounds

* Algorithms

Profiling my prior work revealed something I already suspected: the
bottleneck of my program was the many calls to =rand()=. For this
project, the program has been completely re-factored, not only to use
C++ classes in a loosely coupled, highly cohesive manner, but also to
take advantage of the C++11 =random= library, specifically the
Mersenne Twister engine. All calls to =rand()= have been replaced
with the relevant distributions, such as =uniform_real_distribution=,
=uniform_int_distribution=, =discrete_int_distribution=, and
=normal_distribution=. There is a singleton class object which holds
the random number engine and the random number device object (which can
utilize hardware-based entropy collection if available, but is
otherwise implemented as a PRNG).

Using Apple's XCode profiler, Instruments, I was able to minimize the
time spent on generating random numbers from 75 percent of the running
time to a mere 30 percent, the remaining bottleneck is now the memory
copying of the array of parameters (in the current implement floats,
which showed an improvement from 50 percent to 40 percent running time
compared to doubles), which frankly cannot be "fixed". I managed to
squeeze some more performance out by directly copying my parameter
arrays instead of their containing =Individual= class objects.

The primary data structure used is a C++11 array container, a template
similar to a vector, but more efficient and requiring a size (the
given dimension of thirty). Thus it is an array of thirty parameter
types. This structure is generated, mutated, and owned by the
aforementioned =Individual= class, which uses the
=uniform_real_distribution= to generate random floating point numbers
in the exact domain specified by the various problem functions. It
has a mutate function whose purpose is to bound-check a mutation
operating on any single given gene, and clip it to the individual's
minimum and maximum value if needed. This class can later be derived
to implement an individual whose parameters have varying ranges,
along with accompanying standard deviation mutation factors.

Fitness calculations are performed by the =Problem= class, which first
calculates the raw fitness of the mathematical function, then
normalizes it to the range =[0, 1]=, and ensures that the maximum
fitness value is always one based on a minimization boolean flag
(which flips the fitness if needed). This class owns the relevant
attributes of any given problem: domain, range, minimization, goal,
filter, delta, mutation chance, scaling constant(s), and number of
iterations. It uses the =uniform_real_distribution= class to
efficiently provide random delta values in the range of =[-delta,
delta]=. Also provided is a =potential()= wrapper function which
returns an instance of an =Individual= with the relevant domain
minimum and maximum, and necessary range distribution object.

In this implementation, the algorithm class now owns the full mutation
function(s), as they vary per algorithm. When changing a value, they
make a const function call to the individual for its mutate function,
which, as mentioned previously, checks the boundaries and performs
clipping. The base =Algorithm= class has a mutate method which uses a
=uniform_int_distribution= object to generate an integer in the range
[0, 100], which it then compares to the problem's chance as a
percentage, giving an easy, efficient probabilistic condition. It
loops over the array of parameters, and when the condition is true,
mutates the value of the array by a delta generated by the problem's
=uniform_real_distribution= object.

For reference, the hill-climbing and simulated annealing algorithms
from the first project both run incredibly well now, with the former
achieving a fitness of 0.998 in 1.5 seconds on the Spherical function,
and the latter achieving a fitness of 0.9996 (a raw fitness of 6.8) on
the Schwefel function.

** Genetic Algorithm
*** Population

This implementation of the genetic algorithm uses a generational
population model, composed of 4000 individuals. They are initially
populated with fully random values in the range =[-5.12, 5.12]= for
the Spherical function. To be verbose, the individuals hold an array data
structure of floating point numbers.

*** Selection

To implement the roulette wheel selection mechanism, a "mating pool"
population is made by copying the current population. This is a bad
name, as without a crossover function, no "mating" currently takes
place. Next an array equal in size to the population is created and
filled with the calculated values for each member of the population
(in the same order). The fitness could be an attribute of an
individual, however, an array is necessary in a latter step, and so
was the easier choice.

With the normalized fitnesses recorded, the =std::max_element=
function is used to find the best fitness, returning its location; the
=std::distance= function is then used to determine that element's
index in the array, which corresponds to the location of the best
individual in the population array. This individual is then recorded
as the best. If its fitness beats the problem's goal, the algorithm
is terminated and the best individual is returned to the calling
function (=main=).

The roulette selection routine was trivial to implement thanks to the
=std::discrete_distribution= object, which can accept the front and back
ends of an iterator, and return an integer in the range of =[0, n)=
with the probability of each individual integer equal to the weight
of the integer divided by the sum of all the weights.

The array of fitnesses is sent as the array of weights, and the
possible integers the distribution will return correspond to indices
of the population/mating pool arrays. Thus, by iterating over the
mating pool, and adding elements to it using the random numbers from
the distribution as indices to the original population, the mating
pool is filled with a new selection of individuals biased by fitness
as required by the algorithm.

*** Mutation

With a new selection made, the individuals that compose the
mating pool are then mutated using a specific mutation function owned
by the =GeneticAlgorithm= class. This function creates a
=std::normal_distribution= object using a mean of 0 and standard
deviation of 2. The values of the individual's solution are then
mutated by random values provided by this normal, or Gaussian,
distribution (the bounds checking is of course delegated to the
=Individual= class). This mutation can actually be done concurrently
in the selection process's loop, as once each selection has been
made, it can be mutated immediately without ramifications. Finally,
with the selection and mutation stages complete, the population is
replaced by the mating pool, and a new generation is born.

* Results

These tests were run locally on my MacBook Pro with a 2.5 GHz Intel
Core i5 dual-core (with hyper-threading) processor (but my program is
still currently not threaded, but adding it will be much easier
now).

** Spherical function with goal of 80 percent fitness

#+begin_src text

Solution: (2.053216) (2.106364) (-1.660929) (1.938859) (-3.798331)
(0.101222) (2.431569) (0.500247) (2.192358) (2.543889) (-3.176968)
(-1.752458) (1.753757) (-0.507645) (0.539759) (-1.772312) (2.144157)
(1.421921) (-0.569897) (-0.031749) (-0.084445) (0.830070) (1.885461)
(1.051780) (4.992011) (0.338744) (1.932746) (-2.021140) (0.969577)
(-3.679924)

Normalized fitness: 0.838997
Raw fitness: 126.618
./search  0.09s user 0.01s system 93% cpu 0.107 total

#+end_src

** Spherical function with goal of 90 percent fitness

#+begin_src text

Solution: (2.769581) (-2.244913) (2.959431) (1.858116) (2.365768)
(-2.634073) (-1.108779) (0.429853) (1.673679) (-3.076112) (-0.024376)
(0.712671) (-0.564488) (-1.398184) (-1.040214) (-0.426188) (-1.158640)
(-1.848089) (0.893606) (0.420501) (-2.804287) (0.192525) (0.205753)
(-1.332913) (-0.712808) (-1.455644) (-0.313966) (0.926402) (-1.144152)
(-0.842888)

Normalized fitness: 0.90306
Raw fitness: 76.2364
./search  506.27s user 0.64s system 99% cpu 8:27.35 total
#+end_src

* Conclusion

The Genetic Algorithm is far from complete. An 80 percent fitness is
easy to get, taking a mere 0.107 seconds, but an increase of 10
percent fitness to 90 percent took a whopping 8 minutes, 27.35
seconds. There are many improvements to be made, such as having the
standard deviation attached to each individual and allowing it to
evolve, adding a cross-over, improving the roulette wheel with
windowing or sigma scaling, or even replacing the roulette with a better
selection technique. I find this surprising actually, I expected the
Genetic Algorithm to perform much better than hill-climbing or
simulated annealing; however, those two have been very well tweaked,
while this one has not.

I was up way too late working on this. I certainly did not need to
be, as the implementation of the Genetic Algorithm (without crossover)
took the least bit of my time. It was the object-oriented
re-factoring and integration of =std::random= that took my time, but
I feel it was worth it. The code is available on GitHub at
=https://github.com/andschwa/uidaho-cs472-project=. This course is
making me fall in love with C++, which is a very good thing.
