#+TITLE:     Project #1b Genetic Algorithm
#+AUTHOR:    Andrew Schwartzmeyer
#+EMAIL:     schw2620@vandals.uidaho.edu
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+BEGIN_abstract
This assignment built on Project #2b by adding a simple Genetic
Algorithm. This implementation in C++ used a generational population,
with a unit Gaussian mutation function, and roulette wheel
selection. It faired decently, but has much room for improvement.
#+END_abstract

* Assignment :noexport:
   DEADLINE: <2014-02-21 Fri>
The goal of this project is to write a genetic algorithm (GA) for a
series of benchmark optimization problems. In each case the problem is
to optimize, i.e. find the (global) minimum, of a real valued
function.

To test the GA we'll use 6 standard, benchmark, real-valued functions:

1. Spherical
2. Rosenbrock
3. Rastrigin
4. Schwefel
5. Ackley
6. Griewangk

Each of these functions is defined at [[http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume24/ortizboyer05a-html/node6.html#tabla:DefFunc][here]]. (Note the first function
labeled as Schwefel on this page is actually the double sum, which we
are not using. We are using the Schwefel function defined immediately
after the Rastigin function.)

Pay careful attention to the ranges of the functions. You will want to
use those ranges both in creating intial individuals and in
controlling the generation of neighbors, e.g. you don't want your GA
'wondering' out of the search space. Note that here the functions are
all defined with 30 dimensions, e.g. P = 30 in the function
definitions.

** Task
Write a GA to find the input values (x_{1}, ... ,x_{30}) that minimizes each
of the six benchmark problems.

You need to pick the details of the GA, including:
- Representation
- Fitness function
- Algorithm type: Steady state or generational
- Crossover type: 1-point, 2-point, uniform, arithmetic, etc.
- Mutation rate
- etc.

** Write-up
You must write a short paper describing the results of your project
that includes the following sections:

- Abstract - a short (~200 words) summary of what you did and what the
  results were.
- Algorithm descriptions - clear, complete descriptions of your GA. Be
  careful to include all of the details someone would need to
  replicate your work.
- Examples of necessary details include (there are others):
  - How fitness is measured
  - Exactly how initial random solutions are generated
  - Mutation rates
  - etc.
- Basically every time you make a decision about how the algorithm
  works (what type of crossover it will use, how mutaiton is
  performed, etc.) you should make a note of it.
- Results - you should include graphs and/or tables to make it easy to
  understand the results. Make sure that the graphs and table are
  clearly labeled.
- Conclusions - based on your results draw some specific conclusions
  about how well the algorithm performed.

* Notes :noexport:
** Functions
*** Spherical
- f_{Sph}(x) = (\sum_{i=1})^{p} (x_{i})^{2}
- x_{i} \in [-5.12, 5.12]
- x^{\*} = (0, 0, ..., 0); f_{Sph}(x^{\*}) = 0

Use fewer random restarts, more neighbors

*** Rosenbrock
- f_{Ros}(x) = (\sum_{i=1})^{p-1}[100(x_{i+1} - (x_{i})^{2})^{2} + (x_{i} - 1)^{2}]
- x_{i} \in [-2.048, 2.048]
- x^{\*} = (1, 1, ..., 1); f_{Ros}(x^{\*}) = 0

*** Rastrigin
- f_{Ras}(x) = 10p + (\sum_{i=1})^{p} ((x_{i})^{2} - 10cos(2(\pi)x_{i}))
- x_{i} \in [-5.12, 5.12]
- x^{\*} = (0, 0, ..., 0); f_{Ras}(x^{\*}) = 0

*** Schwefel
f_{Sch}(x) = 418.9829 \cdot p + (\sum_{i=1})^{p} x_{i }sin(\radic|x_{i}|)
x_{i} \in [-512.03, 511.97]
x^{\*} = (-420.9687, ..., -420.9687); f_{Sch}(x^{\*}) = 0

Use more random restarts, fewer neighbors


*** Ackley
- f_{Ack}(x) = 20 + e - 20exp(-0.2\radic((1/p)(\sum_{i=1})^{p}(x_{i})^{2})) - exp((1/p)(\sum_{i=1})^{p}cos(2(\pi)x_{i}))
- x_{i} \in [-30, 30]
- x^{\*} = (0, 0, ..., 0); f_{Ack}(x^{\*}) = 0

*** Griewangk
- f_{Gri}(x) = 1 + (\sum_{i=1})^{p}(x_{i})^{2}/4000 - (\prod_{i=1})^{p}cos(x_{i}/\radic(i))
- x_{i} \in [-600, 600]
- x^{\*} = (0, 0, ..., 0); f_{Gri}(x^{\*}) = 0

* Algorithms

Profiling my prior work revealed something I already suspected: the
bottleneck of my program was the many calls to =rand()=. For this
project, the program has been completely re-factored, not only to use
C++ classes in a loosely coupled, highly cohesive manner, but also to
take advantage of the C++11 =random= library, specifically the
Mersenne Twister engine. All calls to =rand()= have been replaced
with the relevant distributions, such as =uniform_real_distribution=,
=uniform_int_distribution=, =discrete_int_distribution=, and
=normal_distribution=. There is a singleton class object which holds
the random number engine and the random number device object (which can
utilize hardware-based entropy collection if available, but is
otherwise implemented as a PRNG).

Using Apple's XCode profiler, Instruments, I was able to minimize the
time spent on generating random numbers from 75 percent of the running
time to a mere 30 percent, the remaining bottleneck is now the memory
copying of the array of parameters (in the current implement floats,
which showed an improvement from 50 percent to 40 percent running time
compared to doubles), which frankly cannot be "fixed". I managed to
squeeze some more performance out by directly copying my parameter
arrays instead of their containing =Individual= class objects.

The primary data structure used is a C++11 array container, a template
similar to a vector, but more efficient and requiring a size (the
given dimension of thirty). Thus it is an array of thirty parameter
types. This structure is generated, mutated, and owned by the
aforementioned =Individual= class, which uses the
=uniform_real_distribution= to generate random floating point numbers
in the exact domain specified by the various problem functions. It
has a mutate function whose purpose is to bound-check a mutation
operating on any single given gene, and clip it to the individual's
minimum and maximum value if needed. This class can later be derived
to implement an individual whose parameters have varying ranges,
along with accompanying standard deviation mutation factors.

Fitness calculations are performed by the =Problem= class, which first
calculates the raw fitness of the mathematical function, then
normalizes it to the range =[0, 1]=, and ensures that the maximum
fitness value is always one based on a minimization boolean flag
(which flips the fitness if needed). This class owns the relevant
attributes of any given problem: domain, range, minimization, goal,
filter, delta, mutation chance, scaling constant(s), and number of
iterations. It uses the =uniform_real_distribution= class to
efficiently provide random delta values in the range of =[-delta,
delta]=. Also provided is a =potential()= wrapper function which
returns an instance of an =Individual= with the relevant domain
minimum and maximum, and necessary range distribution object.

In this implementation, the algorithm class now owns the full mutation
function(s), as they vary per algorithm. When changing a value, they
make a const function call to the individual for its mutate function,
which, as mentioned previously, checks the boundaries and performs
clipping. The base =Algorithm= class has a mutate method which uses a
=uniform_int_distribution= object to generate an integer in the range
[0, 100], which it then compares to the problem's chance as a
percentage, giving an easy, efficient probabilistic condition. It
loops over the array of parameters, and when the condition is true,
mutates the value of the array by a delta generated by the problem's
=uniform_real_distribution= object.

For reference, the hill-climbing and simulated annealing algorithms
from the first project both run incredibly well now, with the former
achieving a fitness of 0.998 in 1.5 seconds on the Spherical function,
and the latter achieving a fitness of 0.9996 (a raw fitness of 6.8) on
the Schwefel function.

** Genetic Algorithm
*** Population

This implementation of the genetic algorithm uses a generational
population model, composed of 4000 individuals. They are initially
populated with fully random values in the range =[-5.12, 5.12]= for
the Spherical function. To be verbose, the individuals hold an array data
structure of floating point numbers.

*** Selection

To implement the roulette wheel selection mechanism, a "mating pool"
population is made by copying the current population. This is a bad
name, as without a crossover function, no "mating" currently takes
place. Next an array equal in size to the population is created and
filled with the calculated values for each member of the population
(in the same order). The fitness could be an attribute of an
individual, however, an array is necessary in a latter step, and so
was the easier choice.

With the normalized fitnesses recorded, the =std::max_element=
function is used to find the best fitness, returning its location; the
=std::distance= function is then used to determine that element's
index in the array, which corresponds to the location of the best
individual in the population array. This individual is then recorded
as the best. If its fitness beats the problem's goal, the algorithm
is terminated and the best individual is returned to the calling
function (=main=).

The roulette selection routine was trivial to implement thanks to the
=std::discrete_distribution= object, which can accept the front and back
ends of an iterator, and return an integer in the range of =[0, n)=
with the probability of each individual integer equal to the weight
of the integer divided by the sum of all the weights.

The array of fitnesses is sent as the array of weights, and the
possible integers the distribution will return correspond to indices
of the population/mating pool arrays. Thus, by iterating over the
mating pool, and adding elements to it using the random numbers from
the distribution as indices to the original population, the mating
pool is filled with a new selection of individuals biased by fitness
as required by the algorithm.

*** Mutation

With a new selection made, the individuals that compose the
mating pool are then mutated using a specific mutation function owned
by the =GeneticAlgorithm= class. This function creates a
=std::normal_distribution= object using a mean of 0 and standard
deviation of 2. The values of the individual's solution are then
mutated by random values provided by this normal, or Gaussian,
distribution (the bounds checking is of course delegated to the
=Individual= class). This mutation can actually be done concurrently
in the selection process's loop, as once each selection has been
made, it can be mutated immediately without ramifications. Finally,
with the selection and mutation stages complete, the population is
replaced by the mating pool, and a new generation is born.

* Results
* Conclusion
